{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-carter",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "if os.path.abspath('../') not in sys.path:\n",
    "    sys.path.append(os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protective-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "# import pytorch_lightning as pl\n",
    "# from omegaconf import OmegaConf\n",
    "\n",
    "import nemo\n",
    "# import nemo.collections.tts as nemo_tts\n",
    "from nemo.collections.tts.models.base import SpectrogramGenerator, Vocoder\n",
    "from nemo.collections.tts.helpers.helpers import OperationMode\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import soundfile as sf\n",
    "import torchaudio\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc78d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from speech_distances.datasets import load_dataset\n",
    "from speech_distances.models import load_model\n",
    "from speech_distances.dpam import CustomLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8e2467",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 5000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automotive-gather",
   "metadata": {},
   "source": [
    "## Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-supplier",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrogram_generator = SpectrogramGenerator.from_pretrained(\"tts_en_tacotron2\", override_config_path=None)\n",
    "spectrogram_generator.training = False\n",
    "spectrogram_generator.calculate_loss = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-decrease",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = spectrogram_generator.parse('This is a sample text for a deep learning course project.')\n",
    "spectrogram_generator.generate_spectrogram(tokens=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bulgarian-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrograms = spectrogram_generator.generate_spectrogram(tokens=torch.cat((tokens, tokens, tokens, tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "willing-copyright",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocoder = load_model('uniglow', device='cpu')\n",
    "vocoder.eval()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd77c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = torch.load('models/uniglow.model', \n",
    "                   map_location=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f8345",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocoder.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-salon",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms = vocoder.convert_spectrogram_to_audio(spec=spectrograms.cpu()).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-apartment",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(waveforms[0].numpy(), rate=22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582d5a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write('wavs/after_finetune.wav', waveforms[0].numpy(), 22050)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bd69d1",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    (wavs, samplerates,  _, transcripts) = zip(*batch)\n",
    "    new_wavs = []\n",
    "    wav_lens = []\n",
    "    for w in wavs:\n",
    "        idx = np.random.randint(0, w.shape[1]-SEQ_LEN-1)\n",
    "        torch.squeeze(w)[idx:idx+SEQ_LEN]\n",
    "        new_wavs.append(torch.squeeze(w)[idx:idx+SEQ_LEN])\n",
    "    wav_lens = torch.ones(len(new_wavs), dtype=torch.int) * SEQ_LEN\n",
    "    \n",
    "    return torch.stack(new_wavs), wav_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "congressional-postage",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('ljspeech')\n",
    "# dataloader = DataLoader(dataset, batch_size=10, shuffle=False, collate_fn=pad_collate, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "transparent-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(dataset)\n",
    "indices = list(range(dataset_size))\n",
    "validation_split = 0.8\n",
    "split = int(np.floor(validation_split * dataset_size))\n",
    "if 1 :\n",
    "    np.random.seed(1337)\n",
    "    np.random.shuffle(indices)\n",
    "train_indices, valid_indices = indices[split:], indices[:split]\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_dataloader = DataLoader(dataset, \n",
    "                           batch_size=batch_size, \n",
    "                           shuffle=False, \n",
    "                           collate_fn=pad_collate,\n",
    "                           sampler=train_sampler,\n",
    "                           num_workers=4)\n",
    "val_dataloader = DataLoader(dataset, \n",
    "                           batch_size=batch_size, \n",
    "                           shuffle=False, \n",
    "                           collate_fn=pad_collate,\n",
    "                           sampler=valid_sampler,\n",
    "                           num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-times",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = iter(val_dataloader)\n",
    "waveforms, wav_lens= next(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-ordinance",
   "metadata": {},
   "outputs": [],
   "source": [
    "waveforms.shape, wav_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-substance",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(waveforms[0].numpy(), rate=22050)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-priest",
   "metadata": {},
   "source": [
    "## Train Vocoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-belize",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WaveGlow 88M\n",
    "# SqueezeNet 24M\n",
    "# HiFiGan 84M\n",
    "# MelGan 9M\n",
    "# UniGlow 4M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "terminal-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "# vocoder = load_model('uniglow', device='cuda')\n",
    "vocoder = load_model('uniglow', device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-harassment",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.Adam(vocoder.parameters(), lr=1e-4)\n",
    "# logger\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = 'logs/' + current_time\n",
    "summary_writer = tf.summary.create_file_writer(log_dir)\n",
    "custom_loss = CustomLoss(seq_len=SEQ_LEN, stft_loss_coef=0.1, dpam_loss_coef=1.0)\n",
    "\n",
    "max_epoch=30\n",
    "step = 100\n",
    "running_loss = 0.0\n",
    "vocoder.train()\n",
    "for epoch in range(max_epoch):\n",
    "    \n",
    "    if epoch+1 % 5 == 0:\n",
    "        running_dpam_loss = 0.0\n",
    "        running_loss = 0.0\n",
    "        for i, batch in enumerate(val_dataloader, 0):\n",
    "            vocoder.mode = OperationMode.validation\n",
    "            z, logdet, predicted_audio, spec, spec_len = vocoder(audio=waveforms.cuda(), audio_len=wav_lens.cuda())\n",
    "            loss = custom_loss(z=z, logdet=logdet, gt_audio=waveforms.cuda(), predicted_audio=predicted_audio, sigma=1.0)\n",
    "            running_loss += loss.item()\n",
    "            shape_diff = SEQ_LEN - predicted_audio.shape[1]\n",
    "            predicted_audio = F.pad(predicted_audio, (0, shape_diff), mode='constant', value=0)\n",
    "            dpam_loss = torch.mean(model.model_dist.forward(predicted_audio, waveforms.cuda()))\n",
    "            running_dpam_loss += dpam_loss.item()\n",
    "        print('[%d] val loss: %.3f' %\n",
    "                  (epoch+1, running_loss / step))\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('validation loss', \n",
    "                              running_loss/len(val_dataloader), \n",
    "                              step=epoch+1)\n",
    "            tf.summary.scalar('validation dpam loss', \n",
    "                              running_dpam_loss/len(val_dataloader), \n",
    "                              step=epoch+1)\n",
    "        torch.save(vocoder.state_dict(), f'{log_dir}/uniglow_{epoch}.state')\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, batch in enumerate(train_dataloader, 0):\n",
    "        optimizer.zero_grad()\n",
    "        waveforms, wav_lens = batch\n",
    "        vocoder.mode = OperationMode.training\n",
    "        z, logdet, predicted_audio = vocoder(audio=waveforms.cuda(), audio_len=wav_lens.cuda())\n",
    "        loss = custom_loss(z=z, \n",
    "                           logdet=logdet, \n",
    "                           gt_audio=waveforms.cuda(), \n",
    "                           predicted_audio=predicted_audio, \n",
    "                           sigma=1.0)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if i % step == step-1:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch+1, i+1, running_loss / step))\n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar('training loss', running_loss/step, step=i+1)\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "torch.save(vocoder.state_dict(), f'{log_dir}/uniglow_final.state')\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aware-blackjack",
   "metadata": {},
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "planned-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-walnut",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
