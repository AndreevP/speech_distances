{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "center-hepatitis",
   "metadata": {},
   "source": [
    "# Test VCC2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "third-fountain",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "comet_ml is installed but `COMET_API_KEY` is not set.\n",
      "################################################################################\n",
      "### WARNING, path does not exist: KALDI_ROOT=/mnt/matylda5/iveselyk/Tools/kaldi-trunk\n",
      "###          (please add 'export KALDI_ROOT=<your_path>' in your $HOME/.profile)\n",
      "###          (or run as: KALDI_ROOT=<your_path> python <your_script>.py)\n",
      "################################################################################\n",
      "\n",
      "/home/user01/anaconda3/lib/python3.7/site-packages/torchaudio/backend/utils.py:54: UserWarning: \"sox\" backend is being deprecated. The default backend will be changed to \"sox_io\" backend in 0.8.0 and \"sox\" backend will be removed in 0.9.0. Please migrate to \"sox_io\" backend. Please refer to https://github.com/pytorch/audio/issues/903 for the detail.\n",
      "  '\"sox\" backend is being deprecated. '\n",
      "[NeMo W 2021-05-28 19:42:11 experimental:28] Module <class 'nemo.collections.asr.data.audio_to_text_dali.AudioToCharDALIDataset'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n"
     ]
    }
   ],
   "source": [
    "import models\n",
    "import dataset\n",
    "import torch    \n",
    "from collections import OrderedDict\n",
    "\n",
    "def extract_prefix(prefix, weights):\n",
    "    result = OrderedDict()\n",
    "    for key in weights:\n",
    "        if key.find(prefix) == 0:\n",
    "            result[key[len(prefix):]] = weights[key]\n",
    "    return result     \n",
    "\n",
    "\n",
    "ds = dataset.VCC2018DatasetWav2Vec2(list_path='../MOSNet/data/mos_list.txt', data_path='../MOSNet/data/wav/')\n",
    "model = models.Wav2Vec2MOS().cuda()\n",
    "model.load_state_dict(extract_prefix('model.', torch.load('wav2vec2.ckpt')['state_dict']))\n",
    "_=model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prospective-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Model, Wav2Vec2Processor\n",
    "processor = Wav2Vec2Processor.from_pretrained(\"facebook/wav2vec2-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "neither-superior",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [01:20<00:00, 49.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "pred_mos = []\n",
    "gt_mos   = []\n",
    "for i in tqdm.trange(ds.getlen('test')):\n",
    "    signal, mos = ds.getitem('test', i)\n",
    "    x = processor(signal, return_tensors=\"pt\", padding=True, sampling_rate=16000).input_values\n",
    "    with torch.no_grad():\n",
    "        res = model(x.cuda()).mean()\n",
    "    \n",
    "    gt_mos.append(mos.item())\n",
    "    pred_mos.append(res.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "apparent-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "\n",
    "mse = ((np.array(pred_mos)-np.array(gt_mos))**2).mean()\n",
    "lcc = np.corrcoef(np.array(gt_mos), np.array(pred_mos))[0,1]\n",
    "srcc = ss.spearmanr(np.array(gt_mos), np.array(pred_mos))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "innovative-chile",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.samples['test'].columns = ['audio', 'true_mos']\n",
    "df = ds.samples['test'].copy()\n",
    "df['predict_mos'] = np.array(pred_mos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "leading-reasoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sys_df = pd.read_csv('../MOSNet/data/vcc2018_system.csv')\n",
    "df['system_ID'] = df['audio'].str.split('_').str[-1].str.split('.').str[0] + '_' + df['audio'].str.split('_').str[0]\n",
    "result_mean = df[['system_ID', 'predict_mos']].groupby(['system_ID']).mean()\n",
    "mer_df = pd.merge(result_mean, sys_df, on='system_ID')                                                                                                                 \n",
    "\n",
    "sys_true = mer_df['mean']\n",
    "sys_predicted = mer_df['predict_mos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alert-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys_mse = ((sys_true-sys_predicted)**2).mean()\n",
    "sys_lcc = np.corrcoef(sys_true, sys_predicted)[0,1]\n",
    "sys_srcc = ss.spearmanr(sys_true, sys_predicted)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fewer-guard",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Utterance] MSE = 0.7079 LCC = 0.6554 SRCC = 0.6244\n",
      "[System   ] MSE = 0.2302 LCC = 0.9673 SRCC = 0.9337\n"
     ]
    }
   ],
   "source": [
    "print('[Utterance] MSE = {:.4f} LCC = {:.4f} SRCC = {:.4f}'.format(mse, lcc, srcc))\n",
    "print('[System   ] MSE = {:.4f} LCC = {:.4f} SRCC = {:.4f}'.format(sys_mse, sys_lcc, sys_srcc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-ribbon",
   "metadata": {},
   "source": [
    "# Test VCC2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "right-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import StringIO\n",
    "\n",
    "eh1 = pd.read_csv(StringIO('\\n'.join([s.strip().replace(':MOS', '') for s in open('mos_EH1.txt', 'r').readlines()])), sep='\\t')\n",
    "eh2 = pd.read_csv(StringIO('\\n'.join([s.strip().replace(':MOS', '') for s in open('mos_EH2.txt', 'r').readlines()])), sep='\\t')\n",
    "\n",
    "mos_vcc2016 = pd.DataFrame(pd.concat([eh1, eh2]).mean())\n",
    "mos_vcc2016.columns = ['system_mos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "attached-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "vcc2016 = glob.glob('../vcc2016_submissions/*/*.wav')\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'audio': vcc2016,\n",
    "    'system': [s.split('/')[-2] for s in vcc2016]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "desirable-party",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26028/26028 [09:03<00:00, 47.85it/s]\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import scipy.signal\n",
    "\n",
    "def load(path):\n",
    "    signal,sr = librosa.load(path, sr=16000)\n",
    "    return signal\n",
    "\n",
    "    \n",
    "pred_mos = []\n",
    "\n",
    "for i in tqdm.trange(df.shape[0]):\n",
    "    signal = load(df.iloc[i]['audio'])\n",
    "    x = processor(signal, return_tensors=\"pt\", padding=True, sampling_rate=16000).input_values\n",
    "    with torch.no_grad():\n",
    "        res = model(x.cuda()).mean()\n",
    "    \n",
    "    pred_mos.append(res.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "italic-charles",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pred_mos'] = np.array(pred_mos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "comfortable-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_mos = np.array(mos_vcc2016.sort_index()['system_mos'])\n",
    "pred_mos = np.array(df.groupby('system').mean()['pred_mos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "stretch-intervention",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.9769 LCC = 0.9384 SRCC = 0.8571\n"
     ]
    }
   ],
   "source": [
    "def score(gt, pred):\n",
    "    mse = ((gt-pred)**2).mean()\n",
    "    lcc = np.corrcoef(gt, pred)[0,1]\n",
    "    srcc = ss.spearmanr(gt, pred)[0]\n",
    "    print('MSE = {:.4f} LCC = {:.4f} SRCC = {:.4f}'.format(mse, lcc, srcc))\n",
    "    \n",
    "score(gt_mos, pred_mos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-catch",
   "metadata": {},
   "source": [
    "# Test on main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "czech-flexibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "waveglow ...\n",
      "hifigan_v1 ...\n",
      "hifigan_v2 ...\n",
      "hifigan_v3 ...\n",
      "melgan ...\n",
      "val_dataset ...\n",
      "waveglow 3.9508957862854004\n",
      "hifigan_v1 4.0383405685424805\n",
      "hifigan_v2 4.030723571777344\n",
      "hifigan_v3 3.937237501144409\n",
      "melgan 3.645268201828003\n",
      "val_dataset 4.23707389831543\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "model_scores = {}\n",
    "\n",
    "for model_name in ['waveglow', 'hifigan_v1', 'hifigan_v2', 'hifigan_v3', 'melgan', 'val_dataset']:\n",
    "    print(model_name, '...')\n",
    "    model_scores[model_name] = []\n",
    "    for f in os.listdir('to_score/' + model_name):\n",
    "        signal = load(os.path.join('to_score', model_name, f))\n",
    "        x = processor(signal, return_tensors=\"pt\", padding=True, sampling_rate=16000).input_values\n",
    "        with torch.no_grad():\n",
    "            res = model(x.cuda()).mean()\n",
    "            model_scores[model_name].append(res)\n",
    "            \n",
    "for model_name in model_scores:\n",
    "    print(model_name, torch.tensor(model_scores[model_name]).mean().item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
